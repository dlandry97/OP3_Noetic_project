#!/usr/bin/env python3

import rospy
from cv_bridge import CvBridge
from sensor_msgs.msg import Image, CameraInfo
# from robokeeper.msg import Xy_depth
import cv2
import numpy as np
import pyrealsense2 as rs
import apriltags_ros
from apriltags_ros.msg import AprilTagDetectionArray
import csv
from testbed.srv import Plot_points, Reset_plots
# import testbed.srv.plot_points
# import testbed.srv.reset_plots
from std_srvs.srv import Empty, EmptyResponse
import geometry_msgs
from geometry_msgs.msg import TransformStamped 
from tf2_msgs.msg import TFMessage
import matplotlib.pyplot as plt


class GetData(object):
    """ 
    Using the color and depth video streams from the camera, create a contour on the red ball and create three dimensional coordinates 
    """
    def __init__(self):
        #Converts ROS images to a format for OpenCV
        self._bridge = CvBridge()
        #Subscribe to camera_info to get intrinsics data
        rospy.Subscriber("/camera/aligned_depth_to_color/camera_info", CameraInfo, self.get_info)
        #Subcribe to topic that publishes color picture
        rospy.Subscriber("/camera/color/image_raw", Image, self.callback_color)
        #Subcribe to topic that publishes depth picture
        rospy.Subscriber("/camera/aligned_depth_to_color/image_raw", Image, self.callback_depth) # Use this for depth data

        self.time_array = ['Time']
        self.x_array = ['x-axis']
        self.y_array = ['y-axis']
        self.z_array = ['z-axis']

        self.time_flag = False
        self.time_offset = 0.0

        rospy.Subscriber("/tf",TFMessage, self.tag_callback)

        self._plotter = rospy.Service('plot',Plot_points,self.plotter)
        self._quick_plot = rospy.Service('quick_plot',Empty,self.quick_plot)
        self._reset_plots = rospy.Service('reset_plot',Empty,self.reset_plots)
        # self.__get_pose = rospy.Service("getpose",Empty,self.get_pose_cb)


        #Setup publisher for publishing centroid coordinates and depth
        # self.pub = rospy.Publisher("Xy_depth", Xy_depth, queue_size=10)
        #Initialize an initial cx and cy coordinate for the centroid
        self.cx = 0
        self.cy = 0
        
        


    def plotter(self,data):

        self.time_array[1] = 0.0

        rospy.loginfo("Making file called : "+data.plot_name)
        # header = ['name', 'name2']
        try:
            with open('../classes/projects/op3/testbed/apriltag_try/src/testbed/plots/'+data.plot_name+'.csv',"w+") as plotfile:
                plot_writer = csv.writer(plotfile,delimiter=',')#,delimiter=' ',quotechar='|',quoting=csv.QUOTE_MINIMAL)
                # plot_writer.writerow(header)
                # print(self.x_array)
                plot_writer.writerow(self.time_array)
                plot_writer.writerow(self.x_array)
                # plot_writer.writerow(header)
                
                plot_writer.writerow(self.y_array)
                plot_writer.writerow(self.z_array)
            rospy.loginfo("")
        except:
            rospy.logwarn('Error with plotting')

    def quick_plot(self,req):

        fig, ax = plt.subplots(3) 
        ax[0].plot(self.time_array, self.x_array, label = 'x-axis')
        ax[1].plot(self.time_array, self.y_array, label = 'y-axis')
        ax[2].plot(self.time_array, self.z_array, label = 'z-axis')

        
        ax[0].legend()
        ax[1].legend()
        ax[2].legend()
        
       
        ax[0].set_xlabel("Time")
        ax[0].set_ylabel("X")
        ax[1].set_xlabel("Time")
        ax[1].set_ylabel("Y")
        ax[2].set_xlabel("Time")
        ax[2].set_ylabel("Z")
        fig.suptitle("Hip Tracking")

        # fig3, ax3 = plt.subplots()
        # ax3.plot(x,y)
        plt.show()
        
        

        return EmptyResponse()

    def reset_plots(self,req):
        self.time_array = ['Time']
        self.x_array = ['x-axis']
        self.y_array = ['y-axis']
        self.z_array = ['z-axis']
        self.time_flag = False
        self.time_offset = 0.0

        return EmptyResponse()






    def tag_callback(self,data):
        """
        Function:
            Displays a top down view of the robot and ball
        Args:
            img- The color video stream
        Returns:
           None
        """
        
        for tf in data.tf:
            rospy.loginfo('Detected '+tf.child_frame_id)

            if(tf.child_frame_id == 'Tag69'):
                
                bro_time = tf.header.stamp.secs + (tf.header.stamp.nsecs * 0.000000001) - self.time_offset
                if self.time_flag == False:
                    self.time_offset = bro_time
                    self.time_flag = True
                bro_x = tf.transform.translation.x
                bro_y = tf.transform.translation.y
                bro_z = tf.transform.translation.z
                self.x_array.append(float(bro_x))
                self.y_array.append(float(bro_y))
                self.z_array.append(float(bro_z))
                self.time_array.append(float(bro_time))
                print("bro_x = ",bro_x,", bro_y = ",bro_y,", bro_z = ",bro_z)
            
            if(tf.child_frame_id == 'Tag420'):         
                
                start_x = tf.transform.translation.x
                start_y = tf.transform.translation.y
                start_z = tf.transform.translation.z
                self.x_array.append(float(start_x))
                self.y_array.append(float(start_y))
                self.z_array.append(float(start_z))
                print("start_x = ",start_x,", start_y = ",start_y,", start_z = ",start_z)
            
            if(tf.child_frame_id == 'Tag421'):         
                
                fin_x = tf.transform.translation.x
                fin_y = tf.transform.translation.y
                fin_z = tf.transform.translation.z
                self.x_array.append(float(fin_x))
                self.y_array.append(float(fin_y))
                self.z_array.append(float(fin_z))
                print("fin_x = ",fin_x,", fin_y = ",fin_y,", fin_z = ",fin_z)
        
        
        

    def show_img(self, img):
        """ 
        Function:
            Displays a top down view of the robot and ball
        Args:
            img- The color video stream
        Returns:
           None
        """

        # Show video
        cv2.namedWindow("Image", 1)
        cv2.imshow("Image", img)
        cv2.waitKey(3)
    
    def draw_cont(self,img):
        """ 
        Function:
            Draws contours of the red ball as well as a circle and rectangle on the ball in the color video stream
        Args:
            img- The color video stream
        Returns:
           None
        """
        #Convert image to HSV
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        #Range of HSV values for red
        lower_range = np.array([0, 225, 163])
        upper_range = np.array([20, 255, 226])
        #Create mask based on HSV ranges and then dilate and blur
        mask = cv2.inRange(hsv, lower_range, upper_range) 
        kernel = np.ones((7,7), np.uint8)
        mask = cv2.dilate(mask, kernel, iterations=3)
        blur = cv2.GaussianBlur(mask,(5,5),0)

        
        #Draw contours based on blurred mask
        contours, hierarchy = cv2.findContours(blur,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

        try:
            #Find the largest contour
            cnt = max(contours,key=cv2.contourArea)
            
            #Create moment of largest contour
            M = cv2.moments(cnt)

            if len(cnt) > 20:
                #Create a flag for the ball being in frame and set it to 1
                self.ball_flag = 1
                #Find centroid of contour
                self.cx = int(M['m10']/M['m00'])
                self.cy = int(M['m01']/M['m00'])
                #Create a circle and rectangle on the ball
                cv2.circle(img, (self.cx,self.cy), 5, (150,50,100), -1)
                cv2.rectangle(img, (self.cx-25, self.cy-25), (self.cx+25, self.cy+25), (150,50,100), 3)
            else:
                #Indicate that the ball flag is 0 and so the ball is not in frame
                self.ball_flag = 0
        except:
            #Indicate that the ball flag is 0 and so the ball is not in frame
            self.ball_flag = 0
            pass
        # return ball_state
                
    def xyz_from_intrin(self,img,cx,cy):
        """ 
        Function: Creates x,y,z coordiantes from the centoid coordinates and publishes them to the topic Xy_depth with the ball_flag state
        Args:
            img- The depth video stream 
            cx- the x value of the centroid
            cy- the y value of the centroid
        Returns:
           None
        """
        
        result = rs.rs2_deproject_pixel_to_point(self.intrinsics, [cx,cy], img[cy,cx]*0.001)
        print(result)

        # Assemble message to publish x, y, depth data and the ball flag
        # msg = Xy_depth()
        # msg.x = result[0]
        # msg.y = result[1]
        # msg.depth = result[2]
        # msg.flag = self.ball_flag
        # #Publish x, y, and depth data
        # self.pub.publish(msg)


    def get_info(self,data):  
        """ 
        Function: Callback function for geting camera information for intrinsics 
        Args:
            data (sensor_msgs/CameraInfo)
        Returns:
            None
        """
        #Fill in the parameters for instrinsics from camera_info
        self.intrinsics = rs.intrinsics()
        self.intrinsics.width = data.width
        self.intrinsics.height = data.height
        self.intrinsics.ppx = data.K[2]
        self.intrinsics.ppx = data.K[5]
        self.intrinsics.fx = data.K[0]
        self.intrinsics.fy = data.K[4]
        self.intrinsics.model  = rs.distortion.none
        self.intrinsics.coeffs = [0.0, 0.0, 0.0, 0.0, 0.0]
        
    def callback_color(self,data):
        """ 
        Function: Callback function for geting color image from camera
        Args:
            data (sensor_msgs/Image)
        Returns:
            None
        """
        #Get the color image from camera
        color_img = self._bridge.imgmsg_to_cv2(data, "passthrough")
        #convert to RGB
        color_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)
        #Call the draw contour function
        result = self.draw_cont(color_img)
        # coords = self.xyz_from_intrin(self.depth_image,self.cx,self.cy)
        #Show the color image with contours
        # self.show_img(color_img)

    def callback_depth(self,data):
        """ 
        Function: Callback function for getting depth data from aligned depth to color
        Args:
            data (sensor_msgs/Image)
        Returns:
            None
        """
        #Create a depth image from camera. Make it self to be called throughout the code.
        self.depth_image = self._bridge.imgmsg_to_cv2(data, "passthrough")

    
if __name__=="__main__":
    #Initialize the perceoption node
    rospy.init_node("collection")
    #Start GetData
    c = GetData()
    #Prevent the node from stopping
    rospy.spin()